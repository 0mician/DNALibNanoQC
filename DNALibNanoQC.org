* Dataset description
The dataset presented here was gathered in October 2018 and was
analyzed as part of the publication:

[[https://advances.sciencemag.org/content/6/23/eaaz1136][A VersaTile-driven platform for rapid hit-to-lead development of engineered lysins]]

DOI: 10.1126/sciadv.aaz1136

The combinatorial DNA library was created using the VersaTile reaction
and the sequencing library was prepared using the 1D ligation approach
(SQK-LSK108), without barcoding, and sequenced on a Nanopore MinION
device, equiped with a flowcell FLO-MIN109 (R9.4.1). The raw
sequencing data is available in the NCBI SRA database with accession
number SRR.

* Environment
We have provided a requirements.txt file that documents the computing
environment and which can be used with Conda.

#+BEGIN_SRC bash
$ conda create -n DNALibNanoQC --file requirements.txt
#+END_SRC

Other softwares used in this project that are not available through
conda include:

- [[https://nanoporetech.com][Albacore basecaller]]
- [[https://github.com/dpryan79/SE-MEI][SE-MEI]]
- [[https://kirill-kryukov.com/study/tools/fastq-splitter/][Fastq-splitter (optional)]]

For the count tables analysis, we used Rstudio v1.3.959 with R v3.4.4
and the following packages:

- rstudioapi v0.11
- ggplot2 v3.3.1
- plotly v4.9.2.1
- fitdistrplus v1.1-1

* Nanopore Sequencing and Data processing
** Basecalling
The raw sequencing data was basecalled using the software Albacore
v2.3.1 (workflow r94_450bps_linear.cfg). The default Q-score for the
filtering of "pass" reads is 7.

#+BEGIN_SRC bash
$ read_fast5_basecaller.py --flowcell FLO-MIN106 \
                           --kit SQK-LSK108 \
                           --output_format fastq \
                           --worker_threads 32 \
                           --recursive \
                           --files_per_batch_folder 0 \
                           --save_path basecalled
#+END_SRC

In total, 1.68M reads were obtained totalling 6.28 Gbp, with the
following size distribution:

[[./img/WeightedReadLength.png]]

Remark: since 2019, the basecaller guppy is available and recommended.

** Processing of the fastq dataset
*** Alignment of the reads to the destination vector and subsetting
After the assembly reaction, many DNA components are part of the mix
being sequenced with nanopore. In this step, we filter out the
components that do not map to the destination vector (pVTSD2), and
subsequently extract the regions of interest containing the assembly
products.

The pVTSD2 were linearized using the ecl136II restriction enzyme, so
the available fasta sequence of pVTSD2 was rotated to match this
starting/end site, and then indexed using bwa. 

#+BEGIN_SRC bash
$ bwa index -b bwtsw pVTSD2_Linear_ecl136II.fasta
#+END_SRC

Before mapping, we filtered the dataset of reads using NanoFilt, to
keep reads that have around the size of pVTSD2 (7,227 bp), adjusting
for the size of the combinatorial assembly products (the molecular
details can be found in the paper mentioned above, but in short, the
SacB region of about 2,000 bp get substituted with the assembly
products). The size of the assemby product is comprised between 709 bp
and 1186 bp, so we removed the reads that were shorter than 5750 bp
and longer than 6500 bp. This reduced the size of the dataset from
1.68M reads to 200k reads.

#+BEGIN_SRC bash
$ cat reads.fastq | NanoFilt --length 5750 --maxlength 6500 > reads.filtered.fastq 
#+END_SRC

The filtered fastq dataset was then mapped to the vector using bwa
mem. The qualimap command allowed us to estimate the /General error
rate/ to 16%, highlighting the expected error rate found in the single
nanopore reads we obtained.

#+BEGIN_SRC bash
$ bwa mem -t 16 -x ont2d pVTSD2_Linear_ecl136II.fasta reads.filtered.fastq > aln.sam
$ samtools view -b -o aln.bam aln.sam
$ samtools sort -o aln.sorted.bam aln.sam
$ samtools index aln.sorted.bam
$ qualimap bamqc -bam aln.sorted.bam -outfile bamqc.report.pdf --java-mem-size=8G
#+END_SRC

Finally, the reads that mapped to pVTSD2 were further subset. Indeed,
as part of the VersaTile reaction, a part of the vector gets
substituted with the assembled product. It is thus possible to extract
the region that do not map to the vector by looking for reads that are
soft-clipped using the extractSoftClipped command from SE-MEI. We
further filtered the fragments that are between 650 and 1250 bp,
leaving us with [[./reads/blocks.fastq.gz][72k reads]], representing about 4.2% of the original
dataset of reads (1.68M).

#+BEGIN_SRC bash
$ SE-MEI/extractSoftclipped aln.sorted.bam > unmapped.fastq.gz
$ zcat unmapped.fastq.gz | NanoFilt --length 650 --maxlength 1250 > unmapped_650_1250.fastq
#+END_SRC

Remark: minimap2 should be considered instead of bwa-mem. [[https://lh3.github.io/2018/04/02/minimap2-and-the-future-of-bwa][You can find
the rationale for minimap2 over bwa-mem here.]]

* Count tables
We generated the count tables using the python script
[[./DNA_blocks_analysis.py][DNA_blocks_analysis.py]]. The script uses the BioPython library to
manipulate the fastq file and the localms function to align the
components to the reads. Note that this task is slow, but can easily
be parallelized using fastq-splitter and running the script on batches
of reads.

#+BEGIN_SRC bash
$ python DNA_blocks_analysis.py unmapped_650_1250.fastq blocks.csv
#+END_SRC

The general steps are:
- modifying the fasta files of the [[./sequences/][DNA building blocks]] to add the
  position specific linker elements.
- iterate through the reads dataset and align the DNA blocks of each
  position using local alignments.
- calculating the distance between the aligned blocks.
- verifying the synteny of the reads (Flag to 1 if the blocks are too
  distant), and saving the results.

The output (passing) dataset looks like this for the first 2 reads:

| Read Id | Tile Identified  | Tile Length | Align Length | Start | Stop |  Score | Distance | Flag |
|---------+------------------+-------------+--------------+-------+------+--------+----------+------|
|       1 | CecropinAD       |         132 |          132 |    77 |  209 |  526.0 |      -19 |    0 |
|       1 | Flexiblemedian   |          54 |           56 |   190 |  246 |  185.0 |       -6 |    0 |
|       1 | 201j2-1gp229-CBD |         267 |          268 |   240 |  508 | 1211.0 |      -10 |    0 |
|       1 | PVP-SE1gp146-EAD |         561 |          566 |   499 | 1065 | 2298.0 |        0 |    0 |
|       2 | SMAP29           |          99 |          101 |    79 |  180 |  376.0 |       -9 |    0 |
|       2 | Flexiblemedian   |          54 |           54 |   172 |  226 |  209.0 |       -8 |    0 |
|       2 | OBPgp279-CBD     |         396 |          398 |   218 |  616 | 1477.0 |      -36 |    0 |
|       2 | BcepC6Bgp22      |         507 |          477 |   580 | 1057 | 1881.0 |        0 |    0 |
|    etc. |                  |             |              |       |      |        |          |      |

Note: the computation of the local alignment with the function from
BioPython is CPU-bound. However, the task is easily parallelized. We
recommend splitting the fastq file (eg, using fastq-splitter.pl) and
distribute the computation across multiple CPUs.

In the rest of the analysis, we will focus on the pass results. In
order to extract the counts of unique tiles, and combinations, we
simply used the linux tools cut, sort, and uniq:

#+BEGIN_SRC bash
$ tail -n +2 reads_pass.csv |                # ignore header
  cut -d, -f3,5 --output-delimiter=$'\t' |   # take tile names and position
  sort | uniq -c |                           # sort and count 
  awk '{print $2 "\t" $3 "\t" $1}' |         # reorganize results
  sort -nk 2 > count_table_single_blocks.csv  # sort results by position & save
#+END_SRC

| Tile Identified | Position | Count |
|-----------------+----------+-------|
| 3IQ2            |        1 |  1670 |
| Ascaphine       |        1 |  1428 |
| Buforin 1       |        1 |  1601 |
| Cathelicidin    |        1 |  2011 |

For the combinations:
#+BEGIN_SRC bash
$ tail -n +2 blocks.csv |                             # ignore header
  cut -d, -f2 |                                       # extract tile names
  xargs -L 4 |                                        # analyse by groups of 4 lines
  tr " " "_" |                                        # concatenate tile names (by groups of 4)
  sort | uniq -c |                                    # sort and count  
  awk '{print $2 "\t" $1}' |                          # reorganize results  
  sort -r -nk2 > count_table_combinations_tiles.csv   # sort results & save
#+END_SRC

| Tiles combination                               | Count |
|-------------------------------------------------+-------|
| CecropinAD_Flexiblemedian_K11gp3.5_XccBg35      |   115 |
| Sarcotoxin_Flexiblemedian_K11gp3.5_XccBg35      |    97 |
| CecropinAD_Flexiblemedian_EL188-CBD_BcepC6Bgp22 |    77 |
| etc.                                            |       |

Also considering linkers as a single condition:
#+BEGIN_SRC bash
$ tail -n +2 blocks.csv |                             # ignore header
  grep -v "Flexible" |                                # exclude linkers
  cut -d, -f2 |                                       # extract tile names
  xargs -L 3 |                                        # analyse by groups of 3 lines
  tr " " "_" |                                        # concatenate tile names (by groups of 4)
  sort | uniq -c |                                    # sort and count  
  awk '{print $2 "\t" $1}' |                          # reorganize results  
  sort -r -nk2 > count_table_combinations_tiles.csv   # sort results & save
#+END_SRC

| Tiles combination           | Count |
|-----------------------------+-------|
| CecropinAD_K11gp3.5_XccBg35 |   140 |
| Sarcotoxin_K11gp3.5_XccBg35 |   124 |
| etc.                        |       |

* Statistical analysis
We used the R programming environment to showcase some visualizations
and statistics one could use to assess the DNA library. The related
code can be found in the [[./Count_tables_exploration.R][Count_tables_exploration.R]] 

** Individual building blocks analysis
With these graphs, we focus on the blocks independently, by looking
how they distribute within a given position in the assembly:

 [[./img/single_blocks.png]]

We can also focus on a given position, eg position 2 where a linker
element is assembled between the OMP and the CBD. This position has 2
candidate blocks, and we can see the short linker (Flexibleshort) is
not as represented as the long linker (Flexiblelong).

 [[./img/single_blocks_linkers.png]]

** Combinations of building blocks analysis
Here we explore different models to fit the empirical distribution of
our combinations.

[[./img/combinations_blocks_distribution.png]]

We can also explore the same dataset, but making some combinations
single conditions (eg, the linker element in position 2). We also
simplify the exploration by removing a few obvious "non-candidate
distribution models" (eg, uniform and poisson).

[[./img/combinations_blocks_no_linker.png]]
